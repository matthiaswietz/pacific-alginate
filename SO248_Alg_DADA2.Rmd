---
title: "SO248 Alginate mesocosms"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Raw fastq files were obtained from DNASense (Aalborg, DK) and processed on the "aphros" server of the AWI. The raw fastq-files are deposited at ENA under PRJEB61534.

First we remove primers using *Cutadapt*  

```{console}

# Raw fastqs downloaded to directory of choice
# Here: /scratch1/mwietz/SO248_meso/Alginate/
  
cd /scratch1/mwietz/SO248_meso/Alginate/

FILELOCATION="/scratch1/mwietz/SO248_meso/Alginate/" 
NSAMPLE="136" 
module load anaconda2 java 

mkdir Original
mv *.fastq.gz ./Original/
gunzip -f ./Original/*.gz

# copy original files to new file names
mkdir Renamed
ls -1v ./Original/*R1_001.fastq > ./Renamed/originalR1  
ls -1v ./Original/*R2_001.fastq > ./Renamed/originalR2

# DNAsense provides FWD as R2 and REV as R1
# We will rename the other way round for "correct" order
new=1  
for i in $(ls -1v ./Original/*R1_001.fastq)   
do
cp ${i} ./Renamed/${new}"_R2.fastq"
((new++))
done

new=1
for i in $(ls -1v ./Original/*R2_001.fastq)
do
cp ${i} ./Renamed/${new}"_R1.fastq"
((new++))
done  

ls -1v ./Renamed/[0-9]*_R1.fastq > ./Renamed/renamedR1
ls -1v ./Renamed/[0-9]*_R2.fastq > ./Renamed/renamedR2
paste ./Renamed/originalR1 ./Renamed/renamedR2 > ./Renamed/fileID_R2
paste ./Renamed/originalR2 ./Renamed/renamedR1 > ./Renamed/fileID_R1

# Primer clipping 
mkdir Logfiles
mkdir Clipped
CLIP_qsub="/scratch1/mwietz/aphros/ampliconNGS/clipping_aphros.sh"

# Input primer sequences,
# bacterial primer 341F-785R (V3-V4; amplicon length 444)
FBC=CCTACGGGNGGCWGCAG 
RBC=GACTACHVGGGTATCTAATCC 

CCTACGGGNGGCWGCAG
CCTACGGGNGGCWGCAG 
GACTACHVGGGTATCTAATCC
GACTACHVGGGTATCTAATCC

OFWD=16 # length FWD (17) - 1
OREV=20 # length REV (21) - 1
ERROR=0.16 # allowed %mismatches with primer sequences

qsub -d ${FILELOCATION} -t 1-${NSAMPLE} -o ${FILELOCATION}/Logfiles -e ${FILELOCATION}/Logfiles -v FBC=${FBC},RBC=${RBC},OFWD=${OFWD},OREV=${OREV},ERROR=${ERROR} ${CLIP_qsub}

# rename clip-files for uniqueness
# check with -n if renaming looks OK - yes!
cd ./Clipped
rename -n 's/clip/SO248_Alg/' *
  # then rename
rename 's/clip/SO248_Alg/' *
  
# cleaning up directories
mkdir Clipped_logs
mv *.log /Clipped_logs/
mv *.info /Clipped_logs/

# separate Seq-Runs (recommended for dada-error learning)
# move DNAsense IDs 119-136 to separate folder
mkdir Run2
mv {119..136}*.fastq ./Run2

mkdir Run1
mv *fastq Run1

# Write sample.names for dada
cd Run1
ls -1 *_SO248_Alg_R1.fastq | sed 's/_R1\.fastq//' > ../../sample_names_Run1.txt
cd ../Run2
ls -1 *_SO248_Alg_R1.fastq | sed 's/_R1\.fastq//' > ../../sample_names_Run2.txt
cd ../..

# start screen session
screen -S dada

# start R 
module load R/3.5.2 
R

```

*DADA processing of amplicon sequence variants*

```{r, eval=F}

require(dada2)
require(ShortRead)
require(ggplot2)
require(gridExtra)

##########################################

## RUN 1 ##

# setwd
setwd("/scratch1/mwietz/SO248_meso/Alginate/")

# list files
path <- "/scratch1/mwietz/SO248_meso/Alginate/Clipped/Run1"
fns <- list.files(path)
fns

# Sort ensures forward/reverse reads are in same order
fnFs <- sort(list.files(path, pattern="_R1.fastq"))
fnRs <- sort(list.files(path, pattern="_R2.fastq"))

# Extract sample names
sample.names <- sort(read.table(
  "/scratch1/mwietz/SO248_meso/Alginate/sample_names_Run1.txt", 
  h=F, stringsAsFactors=F)$V1)
sample.names

# Specify the full path to the fnFs and fnRs
fnFs <- file.path(path, fnFs)
fnRs <- file.path(path, fnRs)

#################################

# Quality check
QualityProfileFs <- list()
for(i in 1:length(fnFs)) {QualityProfileFs[[i]] <- list()
   QualityProfileFs[[i]][[1]] <- plotQualityProfile(fnFs[i])}
pdf("QualityProfileForward_Run1.pdf")
for(i in 1:length(fnFs)) {
  do.call("grid.arrange", QualityProfileFs[[i]])}
dev.off()
rm(QualityProfileFs)

QualityProfileRs <- list()
for(i in 1:length(fnRs)) {QualityProfileRs[[i]] <- list()
  QualityProfileRs[[i]][[1]] <- plotQualityProfile(fnRs[i])}
pdf("QualityProfileReverse_Run1.pdf")
for(i in 1:length(fnRs)) {
  do.call("grid.arrange", QualityProfileRs[[i]])}
dev.off()
rm(QualityProfileRs)
# most looking okay/quite good

# Make directory and filenames for the filtered fastqs
filt_path <- file.path(path, "../Filtered")
if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(
  filt_path, paste0(sample.names, "_F_filt.fastq"))
filtRs <- file.path(
  filt_path, paste0(sample.names, "_R_filt.fastq"))

#################################

# Filter; set truncLen based on QC output. Other params default

out <- filterAndTrim(
  fnFs, 
  filtFs, 
  fnRs, 
  filtRs,
  truncLen = c(200, 265),
  maxN = 0,
  minQ = 2,
  maxEE = c(3, 3), 
  truncQ = 0, 
  rm.phix = TRUE,
  compress = F,
  multithread = 6)
head(out)
summary(out[, 2]/out[, 1])
# should be retaining >70% (0.8 -- OK here!)

# Quality check 
QualityProfileFs.filt <- list()
for(i in 1:length(filtFs)) 
  {QualityProfileFs.filt[[i]] <- list()
  QualityProfileFs.filt[[i]][[1]] <- plotQualityProfile(
    filtFs[i])}
pdf("QualityProfileForwardFiltered_Run1.pdf")
for(i in 1:length(filtFs)) {do.call(
  "grid.arrange", QualityProfileFs.filt[[i]])}
dev.off()
rm(QualityProfileFs.filt)

QualityProfileRs.filt <- list()
for(i in 1:length(filtRs)) 
  {QualityProfileRs.filt[[i]] <- list()
  QualityProfileRs.filt[[i]][[1]] <- plotQualityProfile(
    filtRs[i])}
pdf("QualityProfileReverseFiltered_Run1.pdf")
for(i in 1:length(filtRs)) {do.call(
  "grid.arrange", QualityProfileRs.filt[[i]])}
dev.off()
rm(QualityProfileRs.filt)

#################################

# Learn errors 
errF <- learnErrors(
  filtFs, multithread=6, randomize=T, 
  verbose=1, MAX_CONSIST=20)
errR <- learnErrors(
  filtRs, multithread=6, randomize=T, 
  verbose=1, MAX_CONSIST=20)

# Plot error profiles
pdf("ErrorProfiles_Run1.pdf")
plotErrors(errF, nominalQ = T)
plotErrors(errR, nominalQ = T)
dev.off()
# convergence after 6/5 rounds: ok!
# only few outliers outside black line - still ok here

# Dereplication 
derepFs <- derepFastq(filtFs, verbose = T)
derepRs <- derepFastq(filtRs, verbose = T)

# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names

# denoising
dadaFs <- dada(
  derepFs, err = errF, multithread = 6, pool = T)
dadaRs <- dada(
  derepRs, err = errR, multithread = 6, pool = T)

#################################

# Read merging
mergers <- mergePairs(
  dadaFs, 
  derepFs, 
  dadaRs,
  derepRs,
  minOverlap = 15,
  verbose = T,
  propagateCol = c(
    "birth_fold","birth_ham"))  #ok: avg >90% merged

# create sequence table
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # identified 86496 sequences
saveRDS(seqtab, 
   "/scratch1/mwietz/SO248_meso/Alginate/seqtab_run1.rds")

# Make stats
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(
  dadaFs, getN), sapply(mergers, getN), 
  rowSums(seqtab))
colnames(track) <- c(
  "input","filtered","denoised","merged","tabled")
rownames(track) <- sample.names
track <- data.frame(track)
head(track)

write.table(
  track, "dadastats_run1.txt", 
  quote = F, sep = "\t")

save.image("SO248_Alg_Run1.Rdata")

##########################################################################

## RUN 2 ##

# list files
path <- "/scratch1/mwietz/SO248_meso/Alginate/Clipped/Run2"
fns <- list.files(path)
fns

# Sort ensures forward/reverse reads are in same order
fnFs <- sort(list.files(path, pattern="_R1.fastq"))
fnRs <- sort(list.files(path, pattern="_R2.fastq"))

# Extract sample names
sample.names <- sort(read.table(
  "/scratch1/mwietz/SO248_meso/Alginate/sample_names_Run2.txt", 
  h=F, stringsAsFactors=F)$V1)
sample.names

# Specify the full path to the fnFs and fnRs
fnFs <- file.path(path, fnFs)
fnRs <- file.path(path, fnRs)

#################################

# Quality check
QualityProfileFs <- list()
for(i in 1:length(fnFs)) {QualityProfileFs[[i]] <- list()
QualityProfileFs[[i]][[1]] <- plotQualityProfile(fnFs[i])}
pdf("QualityProfileForward_Run2.pdf")
for(i in 1:length(fnFs)) {do.call(
  "grid.arrange", QualityProfileFs[[i]])}
dev.off()
rm(QualityProfileFs)

QualityProfileRs <- list()
for(i in 1:length(fnRs)) {QualityProfileRs[[i]] <- list()
QualityProfileRs[[i]][[1]] <- plotQualityProfile(fnRs[i])}
pdf("QualityProfileReverse_Run2.pdf")
for(i in 1:length(fnRs)) {
  do.call("grid.arrange", QualityProfileRs[[i]])}
dev.off()
rm(QualityProfileRs)
# especially R1 not ideal; but acceptable 

# Make directory and filenames for the filtered fastqs
filt_path <- file.path(path, "../Filtered")
if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(
  filt_path, paste0(sample.names, "_F_filt.fastq"))
filtRs <- file.path(
  filt_path, paste0(sample.names, "_R_filt.fastq"))

#################################

# Filter; set truncLen based on QC output. Other params default

out <- filterAndTrim(
  fnFs, 
  filtFs, 
  fnRs, 
  filtRs,
  truncLen = c(200, 265),
  maxN = 0,
  minQ = 2,
  maxEE = c(3, 3), 
  truncQ = 0, 
  rm.phix = TRUE,
  compress = F,
  multithread = 6)
head(out)
summary(out[, 2]/out[, 1])
# should be retaining >70% (>0.8 -- OK here!)

# Quality check 
QualityProfileFs.filt <- list()
for(i in 1:length(filtFs)) 
{QualityProfileFs.filt[[i]] <- list()
QualityProfileFs.filt[[i]][[1]] <- plotQualityProfile(
  filtFs[i])}
pdf("QualityProfileForwardFiltered_Run2.pdf")
for(i in 1:length(filtFs)) {do.call(
  "grid.arrange", QualityProfileFs.filt[[i]])}
dev.off()
rm(QualityProfileFs.filt)

QualityProfileRs.filt <- list()
for(i in 1:length(filtRs)) 
{QualityProfileRs.filt[[i]] <- list()
QualityProfileRs.filt[[i]][[1]] <- plotQualityProfile(
  filtRs[i])}
pdf("QualityProfileReverseFiltered_Run2.pdf")
for(i in 1:length(filtRs)) {do.call(
  "grid.arrange", QualityProfileRs.filt[[i]])}
dev.off()
rm(QualityProfileRs.filt)

#################################

# Learn errors 
errF <- learnErrors(
  filtFs, multithread=6, randomize=T, 
  verbose=1, MAX_CONSIST=20)
errR <- learnErrors(
  filtRs, multithread=6, randomize=T, 
  verbose=1, MAX_CONSIST=20)

# Plot error profiles
pdf("ErrorProfiles_Run2.pdf")
plotErrors(errF, nominalQ = T)
plotErrors(errR, nominalQ = T)
dev.off()
# convergence after 5/5 rounds: ok!
# only few outliers outside black line - still ok here

# Dereplication 
derepFs <- derepFastq(filtFs, verbose = T)
derepRs <- derepFastq(filtRs, verbose = T)

# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names

# denoising
dadaFs <- dada(
  derepFs, err = errF, multithread = 6, pool = T)
dadaRs <- dada(
  derepRs, err = errR, multithread = 6, pool = T)

#################################

# Read merging
mergers <- mergePairs(
  dadaFs, 
  derepFs, 
  dadaRs,
  derepRs,
  minOverlap = 15,
  verbose = T,
  propagateCol = c(
    "birth_fold","birth_ham"))  #ok: avg >90% merged

# create sequence table
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # identified 18878 sequences
saveRDS(seqtab, 
  "/scratch1/mwietz/SO248_meso/Alginate/seqtab_run2.rds")

# Make stats
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(
  dadaFs, getN), sapply(mergers, getN), 
  rowSums(seqtab))
colnames(track) <- c(
  "input","filtered","denoised","merged","tabled")
rownames(track) <- sample.names
track <- data.frame(track)
head(track)

write.table(
  track, "dadastats_run2.txt", 
  quote = F, sep = "\t")

#################################

save.image("SO248_Alg_Run2.Rdata")

```

QC files and intermediate stats show that everything worked well. Negative controls 1&2 contain no reads. NegCtr 3 does - we check later which taxa these correspond to, and whether to remove them from the ASV table.

In the following, sequence tables from the individual DADA processings are combined, chimeras removed and taxonomically classified. 

```{r, eval=F}
setwd("/scratch1/mwietz/SO248_meso/Alginate/")

# Load individual seqtabs 
sq1 <- readRDS(
  "/scratch1/mwietz/SO248_meso/Alginate/seqtab_run1.rds")
sq2 <- readRDS(
  "/scratch1/mwietz/SO248_meso/Alginate/seqtab_run2.rds")

# merge all years/seq-runs
seqtab_full <- mergeSequenceTables(
  sq1,sq2, repeats="error")

# removing chimeras 
# 76615 bimeras out of 97456 input sequences. 
seqtab.nochim <- removeBimeraDenovo(
  seqtab_full, method = "consensus", 
  multithread = 6, verbose = T)

# lots of bimeras - but still OK?
sum(seqtab.nochim)/sum(seqtab_full) #0.87 - OK!

# stats
dim(seqtab.nochim)  # 20841 sequences in 136 samples
summary(rowSums(seqtab.nochim)/rowSums(seqtab_full))

# Determine read lengths/size range of amplicons
table(rep(nchar(colnames(seqtab.nochim)), 
          colSums(seqtab.nochim)))

# Remove singletons and junk sequences
# "c" adjusted to size range of amplicons
seqtab.nochim2 <- seqtab.nochim[, nchar(
  colnames(seqtab.nochim)) %in% c(382:449) & 
    colSums(seqtab.nochim) > 1]

# stats
dim(seqtab.nochim2) # 10332 sequences
summary(rowSums(seqtab.nochim2))
summary(rowSums(seqtab.nochim2)/rowSums(seqtab.nochim))

##########################################################################

## TAXONOMY -- Silva v138 ##

tax_silva138 <- assignTaxonomy(
  seqtab.nochim2, 
  "../../tax_db/silva_nr_v138_train_set.fa.gz", 
  tryRC = TRUE,
  multithread = 10)

#  Bacteria 10265  -- Archaea 60 -- Eukaryota 3 --  NA 4
summary(tax_silva138)

# Remove NA on phylum level
# Remove Chloroplasts & Mitochondria
table(tax_silva138[, 1])   
sum(is.na(tax_silva138[, 2]))   #99 NAs
tax.good <- tax_silva138[
  !is.na(tax_silva138[, 2]) & tax_silva138[, 1] %in% c(
  "Bacteria","Archaea"),]
tax.good <- tax.good[-c(grep(
  "Chloroplast", tax.good[, 4]), grep(
  "Mitochondria", tax.good[, 5])), ]
seqtab.nochim2.good <- seqtab.nochim2[, rownames(tax.good)]
summary(rowSums(seqtab.nochim2.good))

# Format tables
seqtab.nochim2.print <- t(seqtab.nochim2.good)
tax.print <- tax.good
all.equal(
  rownames(seqtab.nochim2.print), 
  rownames(tax.print)) #TRUE
rownames(seqtab.nochim2.print) <- paste(
  "asv", 1:ncol(seqtab.nochim2.good), sep = "")
rownames(tax.print) <- rownames(seqtab.nochim2.print)

# Export
write.table(
  seqtab.nochim2.print, "SO248_Alg_seqtab.txt", sep = "\t", quote=F)
write.table(
  tax.print, "SO248_Alg_tax.txt", sep = "\t", quote=F)
uniquesToFasta(
  seqtab.nochim2.good, "SO248_Alg_asv.fasta")

# save taxdata
save.image("SO248_Alg_tax.Rdata")
```
